{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vrushti07/Synapse/blob/week4/Copy_of_Synapse_LP_Task_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrV0lM70lY4O"
      },
      "source": [
        "# **Task 4**\n",
        "\n",
        "## **DJS Synapse Learning Period**\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2aUIeLKlhsY"
      },
      "source": [
        "Congratulations on making it this far!! Welcome to the world of classification where we move on from unsupervised to helping the algorithms by telling them exactly what the data we're feeding them is. This week we'll be looking into  many algorithms such as Decision Trees, SVC, Naive Bayes, Random Forest and so on. We'll also be delving into hyperparameter tuning the only place where ched chaad can lead to a good result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSVx-4Yhlir1"
      },
      "source": [
        "**Warning: This task contains many theory questions. Proceed with caution!**\n",
        "\n",
        "Jk, make sure you research well and make sure you are understanding the models y'all are implementing as that will make your concepts much stronger and build a strong ML foundation which will be very useful as we move further with the tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6Bj7LLRlmpG"
      },
      "source": [
        "### Overfitting and Underfitting [VERY IMPORTANT]:\n",
        "https://www.youtube.com/watch?v=T9NtOa-IITo\n",
        "Note : This concept can be seen in K Means and decision trees. In fact, we will look deeper into\n",
        "this when we begin deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv3-j_vAltmm"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "io0_TmYnhCDQ",
        "outputId": "380ae003-d181-4e2b-c478-60243aafc4f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk_KrDidlyWv"
      },
      "source": [
        "Use this link to download the adult income dataset and upload it to your drive.\n",
        "\n",
        "https://drive.google.com/file/d/1VAE1qF16D-sKnBOWXzGXVNGhtNZNLFQS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhJ0mqS-mV1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3ef036-7bbd-4d6a-dfee-46740571f5dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7LS__3H4mX0r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "d2f1a1f8-1c60-4ae5-bb15-ce30767929ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       age         workclass  fnlwgt   education  education-num  \\\n",
              "0       39         State-gov   77516   Bachelors             13   \n",
              "1       50  Self-emp-not-inc   83311   Bachelors             13   \n",
              "2       38           Private  215646     HS-grad              9   \n",
              "3       53           Private  234721        11th              7   \n",
              "4       28           Private  338409   Bachelors             13   \n",
              "...    ...               ...     ...         ...            ...   \n",
              "32556   27           Private  257302  Assoc-acdm             12   \n",
              "32557   40           Private  154374     HS-grad              9   \n",
              "32558   58           Private  151910     HS-grad              9   \n",
              "32559   22           Private  201490     HS-grad              9   \n",
              "32560   52      Self-emp-inc  287927     HS-grad              9   \n",
              "\n",
              "           marital-status         occupation   relationship   race     sex  \\\n",
              "0           Never-married       Adm-clerical  Not-in-family  White    Male   \n",
              "1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
              "2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
              "3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
              "4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
              "...                   ...                ...            ...    ...     ...   \n",
              "32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n",
              "32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
              "32558             Widowed       Adm-clerical      Unmarried  White  Female   \n",
              "32559       Never-married       Adm-clerical      Own-child  White    Male   \n",
              "32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
              "\n",
              "       capital-gain  capital-loss  hours-per-week native-country income  \n",
              "0              2174             0              40  United-States  <=50K  \n",
              "1                 0             0              13  United-States  <=50K  \n",
              "2                 0             0              40  United-States  <=50K  \n",
              "3                 0             0              40  United-States  <=50K  \n",
              "4                 0             0              40           Cuba  <=50K  \n",
              "...             ...           ...             ...            ...    ...  \n",
              "32556             0             0              38  United-States  <=50K  \n",
              "32557             0             0              40  United-States   >50K  \n",
              "32558             0             0              40  United-States  <=50K  \n",
              "32559             0             0              20  United-States  <=50K  \n",
              "32560         15024             0              40  United-States   >50K  \n",
              "\n",
              "[32561 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d8c3b33-1224-420a-aa18-461bba5cfadd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32556</th>\n",
              "      <td>27</td>\n",
              "      <td>Private</td>\n",
              "      <td>257302</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Tech-support</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32557</th>\n",
              "      <td>40</td>\n",
              "      <td>Private</td>\n",
              "      <td>154374</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32558</th>\n",
              "      <td>58</td>\n",
              "      <td>Private</td>\n",
              "      <td>151910</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32559</th>\n",
              "      <td>22</td>\n",
              "      <td>Private</td>\n",
              "      <td>201490</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32560</th>\n",
              "      <td>52</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>287927</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>15024</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32561 rows Ã— 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d8c3b33-1224-420a-aa18-461bba5cfadd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d8c3b33-1224-420a-aa18-461bba5cfadd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d8c3b33-1224-420a-aa18-461bba5cfadd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d6c208fe-93b2-431e-8b5d-f7a4c2329d97\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6c208fe-93b2-431e-8b5d-f7a4c2329d97')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d6c208fe-93b2-431e-8b5d-f7a4c2329d97 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_51514ff0-4a5e-4013-b6c5-7ee24813c4e9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_51514ff0-4a5e-4013-b6c5-7ee24813c4e9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 32561,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 17,\n        \"max\": 90,\n        \"num_unique_values\": 73,\n        \"samples\": [\n          28,\n          73,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workclass\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Self-emp-not-inc\",\n          \"Self-emp-inc\",\n          \"State-gov\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fnlwgt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105549,\n        \"min\": 12285,\n        \"max\": 1484705,\n        \"num_unique_values\": 21648,\n        \"samples\": [\n          128485,\n          469907,\n          235951\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Bachelors\",\n          \"HS-grad\",\n          \"Some-college\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education-num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 16,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          13,\n          9,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital-status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Never-married\",\n          \"Married-civ-spouse\",\n          \"Married-AF-spouse\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occupation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"Machine-op-inspct\",\n          \"Protective-serv\",\n          \"Adm-clerical\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relationship\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Not-in-family\",\n          \"Husband\",\n          \"Other-relative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Black\",\n          \"Other\",\n          \"Asian-Pac-Islander\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Female\",\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital-gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7385,\n        \"min\": 0,\n        \"max\": 99999,\n        \"num_unique_values\": 119,\n        \"samples\": [\n          3781,\n          15831\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital-loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 402,\n        \"min\": 0,\n        \"max\": 4356,\n        \"num_unique_values\": 92,\n        \"samples\": [\n          419,\n          2051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hours-per-week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1,\n        \"max\": 99,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          6,\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"native-country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"El-Salvador\",\n          \"Italy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \">50K\",\n          \"<=50K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#import your dataset here\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/adult_income_dataset.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qm-L5ILnBRf"
      },
      "source": [
        "## Dealing with Nan values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEtlUs0umzV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7425c384-d11b-46e8-edbf-fc2c3d345b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32561 entries, 0 to 32560\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   age             32561 non-null  int64 \n",
            " 1   workclass       30725 non-null  object\n",
            " 2   fnlwgt          32561 non-null  int64 \n",
            " 3   education       32561 non-null  object\n",
            " 4   education-num   32561 non-null  int64 \n",
            " 5   marital-status  32561 non-null  object\n",
            " 6   occupation      30718 non-null  object\n",
            " 7   relationship    32561 non-null  object\n",
            " 8   race            32561 non-null  object\n",
            " 9   sex             32561 non-null  object\n",
            " 10  capital-gain    32561 non-null  int64 \n",
            " 11  capital-loss    32561 non-null  int64 \n",
            " 12  hours-per-week  32561 non-null  int64 \n",
            " 13  native-country  31978 non-null  object\n",
            " 14  income          32561 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 3.7+ MB\n"
          ]
        }
      ],
      "source": [
        "#write a code to find the nan values for the dataset and make a decision on whether to dropna or fill na\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtrEPRIlig2L",
        "outputId": "edef2202-7865-4e84-ed21-48230e43ced3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32561 entries, 0 to 32560\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   age             32561 non-null  int64 \n",
            " 1   workclass       32561 non-null  object\n",
            " 2   fnlwgt          32561 non-null  int64 \n",
            " 3   education       32561 non-null  object\n",
            " 4   education-num   32561 non-null  int64 \n",
            " 5   marital-status  32561 non-null  object\n",
            " 6   occupation      32561 non-null  object\n",
            " 7   relationship    32561 non-null  object\n",
            " 8   race            32561 non-null  object\n",
            " 9   sex             32561 non-null  object\n",
            " 10  capital-gain    32561 non-null  int64 \n",
            " 11  capital-loss    32561 non-null  int64 \n",
            " 12  hours-per-week  32561 non-null  int64 \n",
            " 13  native-country  32561 non-null  object\n",
            " 14  income          32561 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 3.7+ MB\n"
          ]
        }
      ],
      "source": [
        "df['workclass'].fillna((df['workclass'].value_counts().mean()),inplace=True)\n",
        "df['occupation'].fillna((df['occupation'].value_counts().mean()),inplace=True)\n",
        "df['native-country'].fillna((df['native-country'].value_counts().mean()),inplace=True)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HNGo6bYnkxV"
      },
      "source": [
        "## Object Valued Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ptjIBF2oLER"
      },
      "source": [
        "For Relationship, Race and Sex find out the max division average fnlwgt for each unique value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw6QmmWJojr6",
        "outputId": "12a7237e-e186-43ef-91bf-b01258bbeba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relationship    race                sex   \n",
            "Husband         Amer-Indian-Eskimo  Male      126480.119565\n",
            "                Asian-Pac-Islander  Male      169612.973171\n",
            "                Black               Male      244901.864382\n",
            "                Other               Male      215741.250000\n",
            "                White               Female    175878.000000\n",
            "                                    Male      184700.296675\n",
            "Not-in-family   Amer-Indian-Eskimo  Female    132342.157895\n",
            "                                    Male      134931.906977\n",
            "                Asian-Pac-Islander  Female    158212.021505\n",
            "                                    Male      159002.363636\n",
            "                Black               Female    200278.417526\n",
            "                                    Male      234694.662736\n",
            "                Other               Female    167190.562500\n",
            "                                    Male      215458.073171\n",
            "                White               Female    183169.122443\n",
            "                                    Male      195293.048408\n",
            "Other-relative  Amer-Indian-Eskimo  Female     62684.200000\n",
            "                                    Male      126705.125000\n",
            "                Asian-Pac-Islander  Female    164926.243902\n",
            "                                    Male      182638.243902\n",
            "                Black               Female    223336.367089\n",
            "                                    Male      241916.988235\n",
            "                Other               Female    194015.230769\n",
            "                                    Male      202569.400000\n",
            "                White               Female    190389.821918\n",
            "                                    Male      214491.032338\n",
            "Own-child       Amer-Indian-Eskimo  Female    105399.000000\n",
            "                                    Male      108545.193548\n",
            "                Asian-Pac-Islander  Female    130772.063291\n",
            "                                    Male      156652.521277\n",
            "                Black               Female    217670.118774\n",
            "                                    Male      247420.251701\n",
            "                Other               Female    173508.681818\n",
            "                                    Male      198517.400000\n",
            "                White               Female    184694.918542\n",
            "                                    Male      195818.682712\n",
            "Unmarried       Amer-Indian-Eskimo  Female     91308.225000\n",
            "                                    Male      128920.277778\n",
            "                Asian-Pac-Islander  Female    153199.640625\n",
            "                                    Male      154287.592593\n",
            "                Black               Female    218098.038576\n",
            "                                    Male      252613.747368\n",
            "                Other               Female    187890.346154\n",
            "                                    Male      227875.636364\n",
            "                White               Female    183005.212432\n",
            "                                    Male      189917.694228\n",
            "Wife            Amer-Indian-Eskimo  Female    139715.894737\n",
            "                Asian-Pac-Islander  Female    136332.666667\n",
            "                Black               Female    209208.692810\n",
            "                Other               Female    139375.312500\n",
            "                White               Female    182134.899924\n",
            "                                    Male      212476.500000\n",
            "Name: fnlwgt, dtype: float64\n",
            "252613.74736842106\n"
          ]
        }
      ],
      "source": [
        "#Write your code here\n",
        "grouped = df.groupby(['relationship', 'race', 'sex'])['fnlwgt'].mean()\n",
        "max_avg_fnlwgt = grouped.max()\n",
        "print(grouped)\n",
        "print(max_avg_fnlwgt)\n",
        "#fnlwgt bascically represents how many people someone in the dataset represents. So, if a person has a weight of 200, it's like saying that this person stands in for 200 people with similar traits in the whole population.\n",
        "#fnlwgt stands for final weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X8TUWd4pJgU"
      },
      "source": [
        "## Getting rid of unnecessary columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjsM8R9TpRTI"
      },
      "source": [
        "*   Drop the education num column since we already have their education in the form of categories\n",
        "*   Check the combinations of the marital-status and relationship column, see if we need both of them or just marital status will work too.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "1DfbhRXppJAf",
        "outputId": "fe1e561f-f753-4731-9e8f-cdb8b94d7714"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age         workclass  fnlwgt  education  education-num  \\\n",
              "0   39         State-gov   77516  Bachelors             13   \n",
              "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
              "2   38           Private  215646    HS-grad              9   \n",
              "3   53           Private  234721       11th              7   \n",
              "4   28           Private  338409  Bachelors             13   \n",
              "5   37           Private  284582    Masters             14   \n",
              "6   49           Private  160187        9th              5   \n",
              "\n",
              "          marital-status         occupation   relationship   race     sex  \\\n",
              "0          Never-married       Adm-clerical  Not-in-family  White    Male   \n",
              "1     Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
              "2               Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
              "3     Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
              "4     Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
              "5     Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
              "6  Married-spouse-absent      Other-service  Not-in-family  Black  Female   \n",
              "\n",
              "   capital-gain  capital-loss  hours-per-week native-country income  \n",
              "0          2174             0              40  United-States  <=50K  \n",
              "1             0             0              13  United-States  <=50K  \n",
              "2             0             0              40  United-States  <=50K  \n",
              "3             0             0              40  United-States  <=50K  \n",
              "4             0             0              40           Cuba  <=50K  \n",
              "5             0             0              40  United-States  <=50K  \n",
              "6             0             0              16        Jamaica  <=50K  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5909e45-3397-4434-a7c9-41eb4e833b7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>37</td>\n",
              "      <td>Private</td>\n",
              "      <td>284582</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>49</td>\n",
              "      <td>Private</td>\n",
              "      <td>160187</td>\n",
              "      <td>9th</td>\n",
              "      <td>5</td>\n",
              "      <td>Married-spouse-absent</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>Jamaica</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5909e45-3397-4434-a7c9-41eb4e833b7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5909e45-3397-4434-a7c9-41eb4e833b7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5909e45-3397-4434-a7c9-41eb4e833b7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ccf10706-7ae0-482c-b688-8b17f823c507\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ccf10706-7ae0-482c-b688-8b17f823c507')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ccf10706-7ae0-482c-b688-8b17f823c507 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 32561,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 17,\n        \"max\": 90,\n        \"num_unique_values\": 73,\n        \"samples\": [\n          28,\n          73,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workclass\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Without-pay\",\n          \"Self-emp-not-inc\",\n          3840.625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fnlwgt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105549,\n        \"min\": 12285,\n        \"max\": 1484705,\n        \"num_unique_values\": 21648,\n        \"samples\": [\n          128485,\n          469907,\n          235951\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Bachelors\",\n          \"HS-grad\",\n          \"Some-college\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education-num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 16,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          13,\n          9,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital-status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Never-married\",\n          \"Married-civ-spouse\",\n          \"Married-AF-spouse\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occupation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Machine-op-inspct\",\n          2194.1428571428573,\n          \"Adm-clerical\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relationship\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Not-in-family\",\n          \"Husband\",\n          \"Other-relative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Black\",\n          \"Other\",\n          \"Asian-Pac-Islander\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Female\",\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital-gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7385,\n        \"min\": 0,\n        \"max\": 99999,\n        \"num_unique_values\": 119,\n        \"samples\": [\n          3781,\n          15831\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital-loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 402,\n        \"min\": 0,\n        \"max\": 4356,\n        \"num_unique_values\": 92,\n        \"samples\": [\n          419,\n          2051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hours-per-week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1,\n        \"max\": 99,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          6,\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"native-country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \"El-Salvador\",\n          \"Philippines\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \">50K\",\n          \"<=50K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#write your code here\n",
        "df.head(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC3ZqfLgzTal"
      },
      "outputs": [],
      "source": [
        "df.drop(['education-num'], axis=1, inplace=True)\n",
        "df.drop(['relationship'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jSOd61Eqwtc"
      },
      "source": [
        "## Dealing with Categorical Data\n",
        "As you probably know by now, the ML models dont know how to deal with String or object type data... so your mission shall you choose to accept it (don't really have much of a choice) is to find out which columns to do one hot encoding on and which columns to do Label Encoding on.\n",
        "\n",
        "**Hint: Since Marital-status has less number of columns, One Hot encode it**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "nsmUrADsr-a3",
        "outputId": "0914fecf-bcec-43e1-e099-47404394c6a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "education: 16\n",
            "occupation: 15\n",
            "native-country: 42\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Encoders require their input argument must be uniformly strings or numbers. Got ['float64', 'str']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0muniques\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'less' did not contain a loop with signature matching types (<class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.StrDType'>) -> None",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e7d168a046b1>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mohe_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_unique\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         return _unique_python(\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;34m\"Encoders require their input argument must be uniformly \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;34mf\"strings or numbers. Got {types}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Encoders require their input argument must be uniformly strings or numbers. Got ['float64', 'str']"
          ]
        }
      ],
      "source": [
        "#Write your code here\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "cols = ['education','occupation','native-country']\n",
        "for i in cols:\n",
        "  print(f'{i}: {len(list(df[i].unique()))}')\n",
        "ohe_cols = ['workclass','marital-status','race','sex']\n",
        "df = pd.get_dummies(df, columns = ohe_cols,dtype = int)\n",
        "for i in cols:\n",
        "      df[i] = le.fit_transform(df[i])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnJF-QlNsfPH"
      },
      "source": [
        "## Altering the Target Column\n",
        "Modify the Target Column (income) to make sure that all the values which are <=50K are replaced with a 0 and the values >50K are replaced with a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaxL40jvsdTV"
      },
      "outputs": [],
      "source": [
        "#write your code here\n",
        "df['income'] = df['income'].apply(lambda x: 0 if x == '<=50K' else 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evdHWcNFtclT"
      },
      "source": [
        "**Extract the target column(income) and store it in a seperate variable and remove it from the original dataset. Additionally, do a 70:30 Train Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_56WtblPtcOQ"
      },
      "outputs": [],
      "source": [
        "#write your code here\n",
        "X=df.drop(['income'], axis=1)\n",
        "y=df['income']\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, random_state=1, test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLWKSyvEuCZx"
      },
      "source": [
        "### Chalo now that we have the preprocessed data we can feed it into the models. Lets start with some basic ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXjaiUZwuQ5c"
      },
      "source": [
        "# Logistic Regression\n",
        "*   Theory:https://www.youtube.com/watch?v=yIYKR4sgzI8&list=PLblh5JKOoLUKxzEP5HA2d-Li7IJkHfXSe\n",
        "*   Implementation: https://www.youtube.com/watch?v=n40hS9tQmcY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SWaCxziuhvD"
      },
      "source": [
        "Explain the algorithm, its working and its use cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBMJdVqmuin-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "dc90938c-bf18-420b-b99f-9bf76921e141"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'Prof-specialty'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-925e0ee4f7f4>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1221\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1224\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         )\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1302\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2082\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m         if (\n\u001b[1;32m   2086\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Prof-specialty'"
          ]
        }
      ],
      "source": [
        "#import the model and apply it to the data\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model=LogisticRegression()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WUCHmTsuxV_"
      },
      "source": [
        "Find the accuracy and confusion matrix for the same and explain what it shows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_EJyGLhu_S6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgLqT8QevAny"
      },
      "source": [
        "# Naive Bayes Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM4crVaFvJiJ"
      },
      "source": [
        "* Theory : https://youtu.be/jS1CKhALUBQ\n",
        "* Theory:\n",
        "https://www.analyticsvidhya.com/blog/2021/09/naive-bayes-algorithm-a-complete-guide-for-data-science-enthusiasts/\n",
        "* Implementation : https://youtu.be/nHIUYwN-5rM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSLP-3qgvKQr"
      },
      "outputs": [],
      "source": [
        "#import the model from sklearn and apply it to your data\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# v=CountVectorizer()\n",
        "# X_train_count=v.fit_transform(X_train.values)\n",
        "# X_train_count.toarray()[:3]\n",
        "\n",
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# modelNB=MultinomialNB()\n",
        "# modelNB.fit(X_train, y_train)\n",
        "\n",
        "# X_test_count=v.transform(X_test)\n",
        "# modelNB.score(X_test, y_test)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hbfnNvEp2vB"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "clf=Pipeline([('vectorizer', CountVectorizer()),('nb', MultinomialNB())])\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWdTN_pUvLaJ"
      },
      "source": [
        "# Decision Tree Classifier\n",
        "* Theory : https://youtu.be/7VeUPuFGJHk\n",
        "* Theory: https://www.analyticsvidhya.com/blog/2021/08/decision-tree-algorithm/\n",
        "* Implementation : https://youtu.be/HY2DcBhgwm0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiI2UVXM-l2O"
      },
      "outputs": [],
      "source": [
        "#import the decision tree from sklearn and run it on your data\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "modeldt = DecisionTreeClassifier(random_state=10)\n",
        "\n",
        "modeldt.fit(X_train,y_train)\n",
        "\n",
        "print(dt_model.score(X_train,y_train))\n",
        "print(dt_model.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k54uCd_M1Mc"
      },
      "source": [
        "<b>Print the Model Accuracy</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMf468Q5-zrX"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmIZRcOpyOV8"
      },
      "source": [
        "## Explain: What are the differences in the working of Logistic Regression, Naive Bayes and Decision Tree and explain why are the accuracies are different.\n",
        "\n",
        "Ans: Working\n",
        "\n",
        "Logistic regression works by fitting a linear equation to the feature set to predict the probability that an input belongs to a particular class. It models the relationship between the features (independent variables) and the log-odds (logarithm of odds) of the target class. Logistic regression assumes that the relationship between the input features and the output label is linear. It estimates probabilities for each class and makes a binary decision based on the probability exceeding a certain threshold (like 0.5).  Naive Bayes uses Bayesâ€™ Theorem to calculate the probability of a class given the input features. Naive Bayes is a generative model, meaning it explicitly models how the data was generated. It uses prior knowledge about the distribution of classes and features to predict the most likely class based on feature values. Despite the independence assumption, it often works well, especially in domains like text classification. A decision tree builds a model by recursively splitting the dataset into subsets based on feature values. At each split, the algorithm selects the feature and threshold that results in the best division of the data.\n",
        "The splitting criterion is based on maximizing some measure of \"purity\" in the resulting subsets.  A decision tree is a non-parametric model that partitions the feature space into regions where each region corresponds to a class. It models complex decision boundaries by splitting the data based on feature values. Each split aims to increase the homogeneity of the classes in the subsets.\n",
        "\n",
        "\n",
        "\n",
        "Why Are the Accuracies Different?\n",
        "The accuracy of each model depends on the nature of the dataset, specifically the distribution of features, the relationships between features, and how the target class can be predicted from these features.\n",
        "\n",
        "Data Distribution:\n",
        "\n",
        "Logistic Regression assumes a linear relationship between features and the target, so if the data is linearly separable, it will perform well. However, if there are non-linear patterns, logistic regression will struggle.\n",
        "Naive Bayes relies on the independence assumption between features. It tends to perform well when this assumption is valid, but if there is significant dependence between features (e.g., correlated features), accuracy will drop.\n",
        "Decision Trees can handle non-linear relationships and interactions between features, which makes them suitable for more complex datasets. However, if the data is noisy or the tree is too deep, it may overfit, leading to lower accuracy on test data.\n",
        "\n",
        "Feature Relationships:\n",
        "\n",
        "Naive Bayes performs well in situations where there is low interaction between features, such as text data, where the presence or absence of words can be treated as independent.\n",
        "Logistic Regression works best when features have a linear relationship with the outcome, which may not hold in all datasets.\n",
        "Decision Trees capture non-linear relationships and interactions between features well, which can improve performance if these patterns are present in the data.\n",
        "\n",
        "Bias vs. Variance:\n",
        "\n",
        "Logistic Regression and Naive Bayes tend to have high bias but low variance, meaning they may underfit but are less prone to overfitting, which makes them more robust on unseen data when the underlying assumptions are met.\n",
        "Decision Trees have low bias but high variance, meaning they can fit the training data very well but are prone to overfitting. This can result in high training accuracy but lower accuracy on test data.\n",
        "\n",
        "Overfitting and Underfitting:\n",
        "\n",
        "Logistic Regression may underfit if the true decision boundary is non-linear.\n",
        "Naive Bayes may underfit if the features are highly correlated.\n",
        "Decision Trees may overfit, especially when the tree becomes too complex (deep), fitting noise in the training data instead of general patterns.\n",
        "Aspect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoS_d9soCS0b"
      },
      "source": [
        "### Mention some real life use cases for each of these three models:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeTGHGb_CbO4"
      },
      "source": [
        "Ans:\n",
        "1. Logistic Regression:\n",
        "\n",
        "Medical Diagnosis: Predicts the likelihood of diseases based on patient data (e.g., heart disease prediction).\n",
        "\n",
        "Credit Scoring: Determines the probability of loan default based on financial factors.\n",
        "\n",
        "Customer Churn Prediction: Predicts if customers will stop using a service.\n",
        "\n",
        "2. Naive Bayes:\n",
        "\n",
        "Spam Detection: Classifies emails as spam or not based on word frequencies.\n",
        "\n",
        "Sentiment Analysis: Analyzes customer feedback to determine positive or negative sentiment.\n",
        "\n",
        "Document Classification: Categorizes documents into topics like news or academic subjects.\n",
        "\n",
        "3. Decision Tree:\n",
        "\n",
        "Customer Segmentation: Groups customers based on purchasing behaviors for targeted marketing.\n",
        "\n",
        "Fraud Detection: Identifies fraudulent transactions by learning complex patterns.\n",
        "\n",
        "Credit Risk Assessment: Classifies loan applicants into risk categories based on financial data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbxfobcUlws6"
      },
      "source": [
        "Now that you have your first result, make sure that you play with the hyperparameters to get a better result. Visualize results, try different hyperparameters by using a loop, GET CREATIVE!<br>\n",
        "\n",
        "Machine learning is an iteritive process. You will have to keep playing with hyperparameters and algorithms. No fixed algorithm will work on a fixed dataset.\n",
        "\n",
        "Take this up as a challenge. The person with the best accuracy wins the round!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou_9m_RqgODP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "9934bc97-40fb-4dde-cfd2-7ecee2ee335f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DecisionTreeClassifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-db1ca0199137>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mdt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mdt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
          ]
        }
      ],
      "source": [
        "#plot a graph that shows the train and test accuracy for increasing depth of the tree (do for 10)\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "for i in range(1,10):\n",
        "  dt_model = DecisionTreeClassifier(max_depth=i, random_state=42)\n",
        "  dt_model.fit(X_train,y_train)\n",
        "  train_accuracy.append(dt_model.score(X_train,y_train))\n",
        "  test_accuracy.append(dt_model.score(X_test,y_test))\n",
        "\n",
        "frame=pd.DataFrame({'max_depth': range(1,10), 'train_acc': train_accuracy, 'test_acc': test_accuracy})\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(frame['max_depth'], frame['train_acc'], marker='o')\n",
        "plt.plot(frame['max_depth'], frame['test_acc'], marker='o')\n",
        "plt.xlabel('Depth of Tree')\n",
        "plt.ylabel('Performance')\n",
        "plt.legend(['train_acc', 'test_acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfuKU5cClGAj"
      },
      "outputs": [],
      "source": [
        "#complete the code below to create an image of the decision tree\n",
        "from sklearn import tree\n",
        "!pip install graphviz\n",
        "decision_tree = tree.export_graphviz(dt_model, out_file='tree.dot', feature_names=X_train.columns, max_depth=2, filled=True)\n",
        "!dot -Tpng tree.dot -o tree.png # to convert the file\n",
        "image = plt.imread('tree.png')\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpSDT-ZlkhRS"
      },
      "source": [
        "<b>print the test accuracy and train accuracy here</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zUFG8T7kkJz"
      },
      "outputs": [],
      "source": [
        "#write code here\n",
        "print(dt_model.score(X_train,y_train))\n",
        "print(dt_model.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oE3O8FSGyDc"
      },
      "source": [
        "### Explain the different hyperparameters you changed and how did it affect the models. Also give a summary of the graphs you made."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJbQ9xvSHMwi"
      },
      "source": [
        "Ans:In decision trees, key hyperparameters significantly affect model performance. The max depth controls how deep the tree grows. A deeper tree allows the model to capture more complex relationships in the training data, improving training accuracy, but it risks overfitting, where the model becomes too specific to the training data. Reducing the depth, on the other hand, helps to prevent overfitting but may result in underfitting, where the model lacks complexity to capture important patterns.\n",
        "\n",
        "The min samples split parameter dictates the minimum number of samples required to split an internal node. A higher value limits the number of splits, resulting in a simpler tree that reduces the risk of overfitting. However, this can decrease the model's accuracy on the training set. A lower value allows for more frequent splits, which creates a deeper, more complex tree, but can lead to overfitting if the splits become too specific.\n",
        "\n",
        "The criterion used for splitting, such as gini or entropy, determines how the decision tree evaluates the quality of each split. While this parameter generally has a smaller impact on overall accuracy, it can influence the structure and speed of the tree's learning process.\n",
        "\n",
        "Graphs like accuracy vs. max depth demonstrate that while training accuracy increases with depth, validation accuracy may plateau or even decrease as overfitting occurs. The confusion matrix and ROC curves help visualize these effects, showing how deeper trees can misclassify data more often due to their overfitting tendencies. The key takeaway is that fine-tuning these hyperparameters can balance tree complexity and generalization, leading to better model performance on unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy4j8BO2mYqR"
      },
      "source": [
        "## Optimizing Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0iMt4WqaFwD"
      },
      "source": [
        "We can even use Ensemble Methods like **bagging (random forest)**, **boosting (adaboost)** and **Pruning** to improve your accuracy. Again creating a loop of hyperparameters and then finding the best among them is a daunting task. To reduce the efforts, we can use a special technique known as **GridSearchCV**. It finds the best hyperparameters for your model without you having to write multiple loops and evaluating them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9bcYWikYkHT"
      },
      "source": [
        "1. GridSearchCV for Random Forest Classifier: https://youtu.be/c4mS7KaOIGY\n",
        "2. GridSearchCV for Adaboost Classifier: https://youtu.be/JmXnztjULnQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oV3eS3lmZs-"
      },
      "source": [
        "### 1. Bagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FiK6cS1wUc3"
      },
      "source": [
        "* Theory : https://www.youtube.com/watch?v=KIOeZ5cFZ50\n",
        "* Theory :\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "* Implementation : https://www.youtube.com/watch?v=MxiktOPmhV8&t=2s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5epQIm8iVWLm"
      },
      "outputs": [],
      "source": [
        "#implement Random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Optional: Generate a classification report for more details\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCGhQvP-TmSd"
      },
      "outputs": [],
      "source": [
        "#find the accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rDAAVrLHqfV"
      },
      "source": [
        "### Explain the difference between random forest and decision tree. Also think of cases where the outputs for both of them can be same if its possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5YxDdkLH2p4"
      },
      "source": [
        "Ans: Difference Between Random Forest and Decision Tree:\n",
        "Model Structure:\n",
        "\n",
        "Decision Tree: A decision tree is a single model that splits the data into branches based on features, ultimately reaching a decision at each leaf node. The tree grows by creating splits based on certain criteria (like gini or entropy) to make predictions. It is prone to overfitting if the tree is too deep or complex, capturing noise in the data.\n",
        "Random Forest: A random forest is an ensemble of multiple decision trees. Instead of relying on a single tree, it builds many decision trees on different subsets of the data and features, then aggregates their predictions (majority voting for classification or averaging for regression). This reduces overfitting and improves generalization because the model learns from various perspectives.\n",
        "Feature Selection:\n",
        "\n",
        "Decision Tree: It considers all available features at each split when growing the tree, which can lead to overfitting if one feature dominates the splits.\n",
        "Random Forest: For each tree, it randomly selects a subset of features to split on. This ensures diversity among the trees and reduces overfitting, as no single feature dominates across the entire forest.\n",
        "Variance and Overfitting:\n",
        "\n",
        "Decision Tree: Since it relies on a single model, a decision tree can easily overfit to the training data if not pruned properly, resulting in high variance.\n",
        "Random Forest: By averaging the results of many trees, random forests reduce variance and prevent overfitting. The randomness in data and feature selection ensures more robust performance.\n",
        "Interpretability:\n",
        "\n",
        "Decision Tree: A single decision tree is interpretable and easy to visualize. It provides a clear decision-making path from input to output, making it useful for understanding feature importance and decisions.\n",
        "Random Forest: While random forests improve performance, they lose interpretability because of the large number of trees. Itâ€™s hard to visualize and understand the decision-making process for hundreds of trees.\n",
        "\n",
        "\n",
        "\n",
        "Cases Where Decision Tree and Random Forest Could Give the Same Output:\n",
        "It is possible for a decision tree and a random forest to give the same output in some cases:\n",
        "\n",
        "\n",
        "Simple or Highly Predictable Data:\n",
        "If the dataset is simple and the relationships between features and the target variable are straightforward, both a single decision tree and the random forest could converge to the same or similar decisions. In such cases, thereâ€™s little to no noise for the random forest to reduce, so the ensemble modelâ€™s benefit diminishes.\n",
        "\n",
        "Small Dataset:\n",
        "When the dataset is small, a decision tree might perform similarly to a random forest because thereâ€™s limited data to benefit from the random sampling of features and instances. Both models might end up learning the same patterns, especially if there's not much variation in the data.\n",
        "\n",
        "Noisy or Non-Informative Features:\n",
        "If the dataset contains features that donâ€™t add much predictive value or are mostly noise, a decision tree and random forest may both struggle and produce similar results. In such a case, the random forestâ€™s multiple trees might not improve performance much over a single decision tree, as all trees may behave similarly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYAY9ky-mo8E"
      },
      "outputs": [],
      "source": [
        "#write a code to implement BaggingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize the base estimator (e.g., Decision Tree)\n",
        "base_estimator = DecisionTreeClassifier()\n",
        "\n",
        "# Initialize the BaggingClassifier\n",
        "bagging_model = BaggingClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the Bagging model\n",
        "bagging_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Optional: Generate a classification report for more details\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s_EC_r9H7_L"
      },
      "source": [
        "### Explain how are Bagging and Random Forest different and why do we do bagging?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbX2UJ8wIKQ-"
      },
      "source": [
        "Ans: Difference Between Bagging and Random Forest:\n",
        "\n",
        "General Concept:\n",
        "\n",
        "Bagging (Bootstrap Aggregating): Bagging is an ensemble method that combines the predictions of multiple models (usually the same type of model, like decision trees) to improve overall performance. Each model is trained on a different subset of the data, created by sampling with replacement (bootstrapping). The final prediction is made by aggregating the predictions of all modelsâ€”using majority voting for classification or averaging for regression.\n",
        "Random Forest: Random Forest is a specialized form of bagging applied specifically to decision trees. It introduces an extra layer of randomness by selecting a random subset of features at each split, in addition to the bootstrapped data sampling. This feature randomness ensures that the trees are even more diverse, reducing correlation between them and improving performance.\n",
        "\n",
        "Feature Selection:\n",
        "\n",
        "Bagging: In vanilla bagging, each model (such as a decision tree) considers all available features for splitting at each node. The only randomness comes from the bootstrapped data.\n",
        "Random Forest: In addition to bootstrapping the data, random forest randomly selects a subset of features at each split of the decision tree. This additional randomness further reduces the correlation between individual trees and improves generalization, especially when the dataset has many strong or correlated features.\n",
        "\n",
        "Algorithm Type:\n",
        "\n",
        "Bagging: Bagging can be applied to any type of model, not just decision trees. For example, you could use bagging with linear regression, SVM, or neural networks.\n",
        "Random Forest: Random forest is specifically designed for decision trees, combining the strengths of decision trees and bagging while incorporating feature randomness.\n",
        "\n",
        "Diversity of Models:\n",
        "\n",
        "Bagging: Bagging ensures diversity by using different bootstrapped samples of the data to train each model. However, if the underlying models are very similar (e.g., decision trees with no depth restriction), they may still produce somewhat similar predictions.\n",
        "Random Forest: In random forests, both bootstrapped data and random feature selection at each split ensure that each tree is more diverse, leading to better overall performance than pure bagging.\n",
        "\n",
        "Why Do We Use Bagging?\n",
        "\n",
        "Reducing Overfitting:\n",
        "\n",
        "Individual models, especially decision trees, are prone to overfitting, meaning they can capture noise and specific patterns in the training data that donâ€™t generalize well to new, unseen data. Bagging reduces overfitting by averaging the predictions from multiple models trained on different subsets of the data. This decreases the model's variance without significantly increasing bias, resulting in more stable and reliable predictions.\n",
        "\n",
        "Improving Model Stability:\n",
        "\n",
        "Bagging increases model robustness by using multiple bootstrapped datasets. Since each model is trained on a slightly different version of the data, the ensemble of models can make better generalizations. Even if some models overfit to noise in their respective datasets, the averaging effect smooths out the noise and leads to more accurate overall predictions.\n",
        "\n",
        "Handling High Variance Models:\n",
        "\n",
        "Models like decision trees are high variance models because they can change drastically with small variations in the data. Bagging works well with high-variance models, as it reduces the variance of the final prediction by averaging over many models.\n",
        "\n",
        "Improved Generalization:\n",
        "\n",
        "By combining the results of multiple models, bagging enhances the model's ability to generalize well to new data. It smooths out individual errors made by overfitting in individual models, leading to better performance on unseen data.\n",
        "\n",
        "Stabilizing Weak Models:\n",
        "\n",
        "Even if the individual models in a bagging ensemble are weak (e.g., shallow decision trees, known as decision stumps), the aggregation of many weak models can lead to a strong, stable model (an idea similar to boosting, though boosting focuses more on model weighting rather than simple averaging)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2fb1YUpmrFU"
      },
      "source": [
        "### 2. Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM1Z1WStwJnk"
      },
      "source": [
        "* Theory : https://www.youtube.com/watch?v=NLRO1-jp5F8&t=724s\n",
        "* Theory :\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
        "*   Theory:https://www.geeksforgeeks.org/ml-xgboost-extreme-gradient-boosting/\n",
        "* Implementation : https://www.youtube.com/watch?v=7xHM93WXOu8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UINCQOrvmvZJ"
      },
      "outputs": [],
      "source": [
        "#write code here\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "abc = AdaBoostClassifier()\n",
        "\n",
        "print(np.mean(cross_val_score(abc,X_train,y_train,scoring='accuracy',cv=42)))\n",
        "print(np.mean(cross_val_score(abc,X_test,y_test,scoring='accuracy',cv=42)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSrXHNqQR9fa"
      },
      "source": [
        "Just to make things more interesting implement XGBoost as well and compare its accuracy with that of AdaBoost :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZW_1FTIiRb3y"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost\n",
        "import xgboost as xgb\n",
        "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qFkTPYOSN6c"
      },
      "source": [
        "### Explain: What is the difference between Adaboost and XGBoost. Also describe in what cases is XGBoost better to use than AdaBoost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKuypd4_Sg_A"
      },
      "source": [
        "Ans: Difference Between AdaBoost and XGBoost:\n",
        "\n",
        "AdaBoost (Adaptive Boosting) is a boosting algorithm that combines weak classifiers (often decision stumps) to create a strong classifier by focusing on misclassified instances in each iteration, adjusting weights accordingly. It typically uses a simple loss function and is sensitive to noisy data and outliers. In contrast, XGBoost (Extreme Gradient Boosting) is a more advanced boosting algorithm that uses decision trees as base learners, employs regularization to prevent overfitting, and optimizes for performance with features like parallel processing and a more complex loss function.\n",
        "\n",
        "When to Use XGBoost Over AdaBoost:\n",
        "\n",
        " XGBoost is preferable in cases where the dataset is large or complex, as it efficiently handles large datasets with high dimensionality and provides better accuracy through its regularization techniques. It also performs better with noisy data, thanks to its robustness and ability to reduce overfitting, making it suitable for competitions and high-stakes scenarios where performance is critical.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDpmiaAazjmm"
      },
      "source": [
        "## Explain: What is the difference between Bagging and Boosting? Explain with examples\n",
        "\n",
        "Ans: Bagging (Bootstrap Aggregating) and Boosting are both ensemble methods used to improve model performance but differ fundamentally in their approach. Bagging, like in Random Forests, involves training multiple models independently on bootstrapped subsets of the data and then aggregating their predictions, which helps reduce variance and is effective for high-variance models like decision trees. In contrast, Boosting focuses on sequentially training models, where each new model aims to correct the errors of the previous ones, giving more weight to misclassified instances. This method reduces both bias and variance, typically leading to better performance, as seen in algorithms like AdaBoost and XGBoost. While Bagging enhances stability, Boosting tends to yield stronger predictive power but requires careful tuning to avoid overfitting.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJqYKCGYmz9U"
      },
      "source": [
        "### 3. Pruning Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOdIrihnI8NC"
      },
      "source": [
        "\n",
        "\n",
        "*   Theory: https://opendatascience.com/what-is-pruning-in-machine-learning/\n",
        "*   Theory:https://towardsdatascience.com/build-better-decision-trees-with-pruning-8f467e73b107\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOr4yjBWq-oe"
      },
      "outputs": [],
      "source": [
        "#implement pruning\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "ccp_alphas = dt_model.cost_complexity_pruning_path(X_train, y_train)[\"ccp_alphas\"]\n",
        "param_grid = {\"ccp_alpha\": ccp_alphas}\n",
        "ccp_grid_alpha_search = GridSearchCV(\n",
        "    estimator=DecisionTreeClassifier(random_state=10),\n",
        "    scoring=make_scorer(accuracy_score),\n",
        "    param_grid=param_grid\n",
        ")\n",
        "ccp_grid_alpha_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXxwy2TFxaAl"
      },
      "outputs": [],
      "source": [
        "#plot a tree (image) similar to one created for decision tree (graphwiz) for the pruning technique\n",
        "ccp_grid_alpha_search.best_params_\n",
        "best_ccp_alpha_tree = ccp_grid_alpha_search.best_estimator_\n",
        "\n",
        "best_decision_tree = tree.export_graphviz(best_ccp_alpha_tree, out_file='best_tree.dot', feature_names=X_train.columns, max_depth=2, filled=True)\n",
        "!dot -Tpng best_tree.dot -o best_tree.png # to convert the file\n",
        "image = plt.imread('best_tree.png')\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQfN8eBtUy16"
      },
      "outputs": [],
      "source": [
        "#write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVNqRQx2j6iO"
      },
      "source": [
        "<b>Note that the accuracy on the test set will be considered and brownie points for *not* overfitting the model in the process</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWMAYEA2rTu-"
      },
      "source": [
        "As a brush up on data visualisation... make a graph to compare the accuracies you achieved for each of the models you trained and explain which one is the best to perform classification tasks and why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6MihN_bT5XZ"
      },
      "outputs": [],
      "source": [
        "#write your code here\n",
        "print(best_ccp_alpha_tree.score(X_train,y_train))\n",
        "print(best_ccp_alpha_tree.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVkfhWnGtEGO"
      },
      "source": [
        "# **Bonus: To be done only if you have completed the above tasks.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOWFtHTStHdm"
      },
      "source": [
        "Ensemble Models are not only used for classification but also for Regression.Research on the various regression models such as XGBoost Regressor and Random Forest regressor and how are they different from the Linear Regression model we made in Task 2. The best research will be edited and featured on the Synapse Instagram page. Happy coding! :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYCwf15ItOTF"
      },
      "source": [
        "# **End of Task**\n",
        "\n",
        "> Â©DJS Synapse 2024 - 2025"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}